import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import joblib
import numpy as np

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv("data/filtered_medicine_info.csv")

# ATC ê·¸ë£¹ë³„ ê°œìˆ˜ ì„¸ê¸°
atc_counts = df['atc_3'].value_counts()

# 2ê°œ ì´ìƒì¸ ATC ê·¸ë£¹ë§Œ ë‚¨ê¸°ê¸°
valid_atcs = atc_counts[atc_counts >= 2].index
df = df[df['atc_3'].isin(valid_atcs)].copy()

# 2. ì„±ë¶„ ì •ì œ í•¨ìˆ˜
def clean_ingredient_list(raw):
    return sorted(list({i.strip().lower() for i in str(raw).split('/') if i.strip()}))

df['ing_list'] = df['ing_en'].fillna('').apply(clean_ingredient_list)

# 3. ë²¡í„°í™”ìš© ë¬¸ìì—´ ìƒì„±
df['joined_ings'] = df['ing_list'].apply(lambda x: ' | '.join(x))

# 4. CountVectorizer ì ìš© (multi-hot encoding)
def pipe_split_tokenizer(text):
    return text.split(' | ')

vectorizer = CountVectorizer(tokenizer=pipe_split_tokenizer)
X = vectorizer.fit_transform(df['joined_ings'])

# 5. ë¼ë²¨ ì¸ì½”ë”© (ATC ì½”ë“œ â†’ ìˆ«ì)
le = LabelEncoder()
y = le.fit_transform(df['atc_3'])

# í¬ì†Œ í–‰ë ¬ â†’ numpy ë°°ì—´ë¡œ ë³€í™˜
X_values = X.toarray()
y_values = y

# í›ˆë ¨/ê²€ì¦ ë¶„í• 
X_train, X_val, y_train, y_val = train_test_split(
    X_values, y_values, test_size=0.2, random_state=42, stratify=y_values
)

# DMatrix ë³€í™˜
dtrain = xgb.DMatrix(X_train, label=y_train)
dval = xgb.DMatrix(X_val, label=y_val)

# í•˜ì´í¼íŒŒë¼ë¯¸í„°
params = {
    "objective": "multi:softprob",
    "num_class": len(le.classes_),
    "eval_metric": "mlogloss",
    "max_depth": 6,
    "eta": 0.1,
    "seed": 42
}

# í•™ìŠµ
evallist = [(dtrain, 'train'), (dval, 'eval')]
xgb_model = xgb.train(params, dtrain, num_boost_round=100, evals=evallist, early_stopping_rounds=10)

# ì €ì¥
xgb_model.save_model("xgb_atc_model.json")


joblib.dump(vectorizer, "vectorizer.pkl")
joblib.dump(le, "label_encoder.pkl")

# ğŸ”¸ ì €ì¥ëœ ë²¡í„°ë¼ì´ì €ì™€ ë¼ë²¨ì¸ì½”ë”ê°€ í•„ìš”í•˜ë¯€ë¡œ ë¯¸ë¦¬ ì €ì¥í•´ë‘ì (í›ˆë ¨ ì‹œ ì €ì¥í–ˆë‹¤ë©´ ì—¬ê¸°ì„œ ë¡œë“œ)
# joblib.dump(vectorizer, 'vectorizer.pkl')
# joblib.dump(le, 'label_encoder.pkl')

# ğŸ”¸ ë¡œë“œ
vectorizer = joblib.load("vectorizer.pkl")
le = joblib.load("label_encoder.pkl")
model = xgb.Booster()
model.load_model("xgb_atc_model.json")

# ğŸ”¸ ì˜ˆì¸¡ í•¨ìˆ˜
def predict_atc_from_ingredients(ingredients: list):
    # ì„±ë¶„ ì •ì œ ë° ë²¡í„°í™”
    ingredients = sorted(list({i.strip().lower() for i in ingredients if i.strip()}))
    input_str = ' | '.join(ingredients)
    vec = vectorizer.transform([input_str])

    # ì˜ˆì¸¡
    dmatrix = xgb.DMatrix(vec)
    probs = model.predict(dmatrix)[0]
    pred_idx = np.argmax(probs)
    pred_atc = le.inverse_transform([pred_idx])[0]

    # ê²°ê³¼ ì¶œë ¥
    return {
        "ì…ë ¥ ì„±ë¶„": ingredients,
        "ì˜ˆì¸¡ ATC": pred_atc,
        "í™•ë¥  TOP 3": [
            {"ATC": le.inverse_transform([i])[0], "í™•ë¥ ": round(prob, 3)}
            for i, prob in sorted(enumerate(probs), key=lambda x: -x[1])[:3]
        ]
    }
