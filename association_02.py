from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import fpgrowth, association_rules
import pandas as pd
from eda_01 import selected_groups, atc_group_cutoff

# ì—°ê´€ ê·œì¹™ ì ìš© ê²°ê³¼ ì €ì¥ dictionary ì„¤ì •
fp_results = {}
rules_results = {}
single_rules_results = {}
multi_rules_results = {}


for atc_code in selected_groups:
    print(f"\nğŸ” ATC ê·¸ë£¹: {atc_code}")
    group_df = atc_group_cutoff[atc_group_cutoff['atc_3'] == atc_code]

    # ì£¼ì„±ë¶„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬
    transactions = group_df['ing_en'].dropna().apply(
        lambda x: [i.strip().lower() for i in x.split('/') if i.strip()]
    ).tolist()

    if len(transactions) == 0:
        print("âš ï¸ íŠ¸ëœì­ì…˜ ì—†ìŒ â†’ ê±´ë„ˆëœ€")
        continue

    # ì „ì²´ ì„±ë¶„ ë¹ˆë„ ê¸°ì¤€ ìƒìœ„ 50ê°œë§Œ ì‚¬ìš©
    all_ingredients = [i for sublist in transactions for i in sublist]
    top_50 = pd.Series(all_ingredients).value_counts().head(50).index.tolist()

    # ì›-í•« ì¸ì½”ë”©(ì£¼ì„±ë¶„ì´ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0)
    te = TransactionEncoder()
    te_arr = te.fit(transactions).transform(transactions)
    df = pd.DataFrame(te_arr, columns=te.columns_)[top_50]

    # FP-Growth ì‹¤í–‰ + ìµœëŒ€ ì¡°í•© ìˆ˜ 3ê°œë¡œ ì œí•œ(ì¼ë°˜ OTC ì¡°í•© ì£¼ì„±ë¶„ 2~3ê°€ì§€)
    freq_items = fpgrowth(df, min_support=0.1, use_colnames=True, max_len=3)
    if freq_items.empty:
        continue
    fp_results[atc_code] = freq_items

    # ì—°ê´€ ê·œì¹™ ì¶”ì¶œ
    rules = association_rules(freq_items, metric="lift", min_threshold=1.0)
    if rules.empty:
        continue
    rules_results[atc_code] = rules

    # ë‹¨í•­ ê·œì¹™ (1:1)
    single_rules = rules[
        (rules['antecedents'].apply(len) == 1) &
        (rules['consequents'].apply(len) == 1)
    ]
    single_rules_results[atc_code] = single_rules

    # ë‹¤í•­ ê·œì¹™ (2+:1 or N:M)
    multi_rules = rules[
        (rules['antecedents'].apply(len) > 1) |
        (rules['consequents'].apply(len) > 1)
    ]
    multi_rules_results[atc_code] = multi_rules

    print(f"âœ… ë‹¨í•­ {len(single_rules)}ê°œ, ë‹¤í•­ {len(multi_rules)}ê°œ ê·œì¹™ ì¶”ì¶œ ì™„ë£Œ")


"""
ì—°ê´€ ê·œì¹™ ê¸°ë°˜ ìµœì  ì¡°í•© ë¦¬ìŠ¤íŠ¸ ì •ë¦¬
"""

# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
summary_rows = []

# ê¸°ì¤€ê°’(í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •í•  ê²ƒ)
min_support = 0.1 #ìµœì†Œ ì§€ì§€ë„
min_confidence = 0.6 #ìµœì†Œ ì‹ ë¢°ë„
min_lift = 1.5 #ìµœì†Œ í–¥ìƒë„
top_n = 5  # ê° ê·¸ë£¹ë‹¹ ìƒìœ„ 5ê°œ rule ì¶”ì¶œ

for atc_code in selected_groups:
    # ê·œì¹™ì´ ì—†ëŠ” ê·¸ë£¹ì€ ì œì™¸
    if atc_code not in rules_results:
        continue
    rules_df = rules_results[atc_code]
    if rules_df.empty:
        continue

    # í•„í„°ë§ëœ ì—°ê´€ ê·œì¹™ ì¶”ì¶œ
    filtered = rules_df[
        (rules_df['support'] >= min_support) &
        (rules_df['confidence'] >= min_confidence) &
        (rules_df['lift'] >= min_lift)
    ]
    # print(f"âœ… {atc_code}: {len(filtered)}ê°œì˜ í•„í„°ëœ ë£°")

    if filtered.empty:
        continue

    # lift ê¸°ì¤€ ì •ë ¬ â†’ ìƒìœ„ Nê°œ ì¶”ì¶œ
    top_rules = filtered.sort_values(by='lift', ascending=False).head(top_n)

    # ê²°ê³¼ ì •ë¦¬
    for _, row in top_rules.iterrows():
        summary_rows.append({
            'ATC ê·¸ë£¹': atc_code,
            'Antecedents': ', '.join(sorted(row['antecedents'])),
            'Consequents': ', '.join(sorted(row['consequents'])),
            'support': round(row['support'], 3),
            'confidence': round(row['confidence'], 3),
            'lift': round(row['lift'], 3)
        })

# ê²°ê³¼ DataFrame ìƒì„±
rules_summary_df = pd.DataFrame(summary_rows)
print(rules_summary_df.head(20))  # ì•ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸°

# ì—°ê´€ ê·œì¹™ ê²°ê³¼ ì €ì¥
rules_summary_df.to_csv("atc_rule_summary.csv", index=False)